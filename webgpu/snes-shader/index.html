<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>SNES shader</title>
  <link id="shader" rel="preload" type="text/wgsl" href="./shaders/shader.wgsl" as="fetch" crossorigin="anonymous">
  <style>
    body {
      background-color: hsl(0 0% 50%);
      font-family: Verdana, Geneva, Tahoma, sans-serif;
    }

    canvas, img {
      /* Make sure the browser doesn't do any of its own filtering */
      image-rendering: pixelated;
    }

    figure canvas, figure img {
      border: solid 1px black;
    }
  </style>
</head>
<body>
  <h1>SNES shader</h1>
  <figure>
    <!--
      The SNES default render resolution was 256x224 px, but the SNES had a 8/7 pixel aspect ratio
      on NTSC (ref: https://gaming.stackexchange.com/a/318959). So the apparent size is 256x196 px.

      878x672 = [(256 * (8/7)) * 3, 224 * 3] fit neatly into 720p
    -->
    <canvas id="canvas" width="878" height="672">Canvas not supported</canvas>
    <figcaption>Filtered (scaled 3x)</figcaption>
  </figure>
  <figure>
    <img id="source" height="672" src="resources/dkc2.png">
    <figcaption>Original (scaled 3x)</figcaption>
  </figure>
  <script type="module">
    // Render quad: array<vec2<f32>>
    const quad = new Float32Array([
      // upper triangle
      0.0, 1.0,
      1.0, 0.0,
      1.0, 1.0,

      // lower triangle
      0.0, 0.0,
      1.0, 0.0,
      0.0, 1.0,
    ]);

    // Uniform data
    const uniformData = new Float32Array([
      // viewProjection: mat4x4<f32> (fill viewport)
      2.0, 0.0, 0.0, 0.0,
      0.0, 2.0, 0.0, 0.0,
      0.0, 0.0, 2.0, 0.0,
      -1.0, -1.0, 0.0, 1.0,
    ]);

    // Draw indices for vertex ordering
    const indices = new Uint16Array([0, 1, 2, 3, 4, 5]);

    /**
     * Main function
     */
    async function main() {
      const adapter = await navigator.gpu?.requestAdapter();
      const device = await adapter?.requestDevice({
        requiredLimits: {},
        requiredFeatures: [],
      });
      if (!device) {
        throw new Error('WebGPU not supported');
      }

      const canvas = document.getElementById('canvas');
      const context = canvas.getContext('webgpu');
      const queue = device.queue;

      // Helper for creating GPU buffers
      function createBuffer(arr, usage) {
        const buffer = device.createBuffer({
          size: (arr.byteLength + 3) & ~3,
          usage,
          mappedAtCreation: true,
        });

        const writeArray = arr instanceof Uint16Array ? new Uint16Array(buffer.getMappedRange()) : new Float32Array(buffer.getMappedRange());
        writeArray.set(arr);
        buffer.unmap();

        return buffer;
      }

      // Helper for loading shaders
      async function loadShader(url) {
        const result = await fetch(url);
        if (!result.ok) {
          throw new Error(`Unable to fetch ${url}: HTTP ${result.status} ${result.statusText}`);
        }

        const shaderCode = await result.text();

        return device.createShaderModule({ label: url, code: shaderCode });
      }

      // Load image bitmap
      async function loadImageBitmap(url) {
        const response = await fetch(url);
        const blob = await response.blob();

        return await createImageBitmap(blob, { colorSpaceConversion: 'none' });
      }

      const presentationFormat = navigator.gpu.getPreferredCanvasFormat();
      context.configure({
        device: device,
        format: presentationFormat,
        usage: GPUTextureUsage.RENDER_ATTACHMENT | GPUTextureUsage.COPY_SRC,
        alphaMode: 'opaque',
      });

      // Buffers for rendering quad
      const positionBuffer = createBuffer(quad, GPUBufferUsage.VERTEX);
      const indexBuffer = createBuffer(indices, GPUBufferUsage.INDEX);
      const uniformBuffer = createBuffer(uniformData, GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST);

      // Source image texture
      const source = document.getElementById('source');
      const bitmap = await loadImageBitmap(source.src);
      const imageTexture = device.createTexture({
        format: 'rgba8unorm',
        size: [bitmap.width, bitmap.height],
        usage: GPUTextureUsage.TEXTURE_BINDING | GPUTextureUsage.COPY_DST | GPUTextureUsage.RENDER_ATTACHMENT,
      });
      queue.copyExternalImageToTexture({ source: bitmap }, { texture: imageTexture }, { width: bitmap.width, height: bitmap.height });

      // Intermediate texture for filtering
      const intermediateTexture = device.createTexture({
        format: 'rgba8unorm',
        size: [bitmap.width, bitmap.height],
        usage: GPUTextureUsage.TEXTURE_BINDING | GPUTextureUsage.RENDER_ATTACHMENT,
      });

      const shaderPreload = document.getElementById('shader');
      const shaderModule = await loadShader(shaderPreload.href);

      // This pipeline does the horizontal chroma subsampling
      const pipeline1 = device.createRenderPipeline({
        layout: "auto",
        vertex: {
          module: shaderModule,
          entryPoint: 'vertShader',
          buffers: [
            // position
            {
              attributes: [
                {
                  shaderLocation: 0, // @location(0)
                  offset: 0,
                  format: 'float32x2',
                }
              ],
              arrayStride: 4 * 2, // sizeof(float) * 2
              stepMode: 'vertex',
            },
          ],
        },
        fragment: {
          module: shaderModule,
          entryPoint: 'fragShader1',
          targets: [
            { format: intermediateTexture.format },
          ],
        },
        primitive: {
          frontFace: 'cw',
          cullMode: 'none',
          topology: 'triangle-list',
        },
      });

      const bindGroup1 = device.createBindGroup({
        layout: pipeline1.getBindGroupLayout(0),
        entries: [
          { binding: 0, resource: device.createSampler() },
          { binding: 1, resource: imageTexture.createView() },
          { binding: 2, resource: { buffer: uniformBuffer }},
        ],
      });

      // This pipeline applies chromatic abberation
      const pipeline2 = device.createRenderPipeline({
        layout: "auto",
        vertex: {
          module: shaderModule,
          entryPoint: 'vertShader',
          buffers: [
            // position
            {
              attributes: [
                {
                  shaderLocation: 0, // @location(0)
                  offset: 0,
                  format: 'float32x2',
                }
              ],
              arrayStride: 4 * 2, // sizeof(float) * 2
              stepMode: 'vertex',
            },
          ],
        },
        fragment: {
          module: shaderModule,
          entryPoint: 'fragShader2',
          targets: [
            { format: presentationFormat },
          ],
        },
        primitive: {
          frontFace: 'cw',
          cullMode: 'none',
          topology: 'triangle-list',
        },
      });

      const bindGroup2 = device.createBindGroup({
        layout: pipeline2.getBindGroupLayout(0),
        entries: [
          { binding: 0, resource: device.createSampler({ magFilter: 'linear' }) },
          { binding: 1, resource: intermediateTexture.createView() },
          { binding: 2, resource: { buffer: uniformBuffer }},
        ],
      });

      // Called once per frame
      async function render() {
        // Get the current canvas backing texture
        const colorTexture = context.getCurrentTexture();

        // Command buffer
        const commandEncoder = device.createCommandEncoder();

        const pass1 = commandEncoder.beginRenderPass({
          colorAttachments: [
            {
              view: intermediateTexture.createView(),
              clearValue: { r: 0, g: 0, b: 0, a: 1 },
              loadOp: 'clear',
              storeOp: 'store',
            },
          ],
        });
        pass1.setPipeline(pipeline1);
        pass1.setBindGroup(0, bindGroup1);
        pass1.setVertexBuffer(0, positionBuffer);
        pass1.setIndexBuffer(indexBuffer, 'uint16');
        pass1.drawIndexed(6);
        pass1.end();

        const pass2 = commandEncoder.beginRenderPass({
          colorAttachments: [
            {
              view: colorTexture.createView(),
              clearValue: { r: 0, g: 0, b: 0, a: 1 },
              loadOp: 'clear',
              storeOp: 'store',
            },
          ],
        });
        pass2.setPipeline(pipeline2);
        pass2.setBindGroup(0, bindGroup2);
        pass2.setVertexBuffer(0, positionBuffer);
        pass2.setIndexBuffer(indexBuffer, 'uint16');
        pass2.drawIndexed(6);
        pass2.end();

        queue.submit([ commandEncoder.finish() ]);

        // Request being called again
        requestAnimationFrame(render);
      }

      // Start rendering
      requestAnimationFrame(render);
    }

    window.addEventListener('load', () => {
      // Just rethrow any async error
      main().catch(err => { throw err; });
    })
  </script>
</body>
</html>
